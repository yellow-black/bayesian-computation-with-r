---
title: "chapter2"
author: "s-takano"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
set.seed(29)
```

```{r library}
library(LearnBayes)
```

## 2-1

### 事前分布の設定

```{r}
p = seq(0, 1, by=0.125)
prior = c(0.001, 0.001, 0.950, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008)
sum(prior)
```

### 尤度関数

```{r}
likelihood = function (p) p ^ 6 * (1 - p) ^ 4
```

### 事後分布

```{r}
posterior = c()
for (i in 1:length(p)) {
  posterior = c(posterior, likelihood(p[i]) * prior[i]) 
}
posterior = posterior / sum(posterior)
round(cbind(p, prior, posterior), 3)
```

## 2-2

### 事前分布

```{r}
midpt = seq(0.05, 0.95, by = 0.1)
prior = rep(0.1, 10) # 無情報事前分布
curve(histprior(x, midpt, prior), from = 0, to = 1)
```

### 事後分布

```{r}
p = seq(0, 1, length = 500)
posterior = c()
for (i in length(p)) {
  min_idx = which.min(abs(midpt - p[i]))
  posterior = c(posterior, dbeta(p, 10, 10) * prior[min_idx]) # コイン Head 10, Tail = 10 
}
posterior = posterior / sum(posterior)
ps = sample(p, replace = TRUE, prob = posterior)
hist(ps)
```

## 2-3

### 事前分布 

```{r}
p = seq(0, 1, length=100)
plot(p, dbeta(p, 1, 1), type ="l")
```

### 事後分布

```{r}
p = seq(0, 1, length=100)
plot(p, dbeta(p, 23, 8), type ="l")
```

### (a)

```{r}
qbeta(c(0.5, 0.95), 23, 8)
```

### (b)

```{r}
q = seq(0, 1, length=100)
plot(q, pbeta(q, 23, 8), type ="l")
```

```{r}
1 - pbeta(0.6, 23, 8)
```

### (c)

```{r}
sample = rbeta(1000, 23, 8)
sample[1:100]
```

### (d)

さらに、10人いる場合の高校を卒業する人数 $X$ の予測分布を求める．

$$
p(x) = \int_{0}^{1} \binom{10}{x}p^{x}(1-p)^{10-x} Beta(p|23,8) dp
$$

$$
\begin{aligned}
  p(X=9) 
  &= \int_{0}^{1} \binom{10}{9}p^{9}(1-p)^{10-9} Beta(p|23,8) dp \\
  &= \int_{0}^{1} 10 \cdot p^{9}(1-p) Beta(p|23,8) dp \\
  &= \frac{10}{B(23, 8)} \int_{0}^{1} p^{9}(1-p) p^{22} (1-p)^{7} dp \\
  &= \frac{10}{B(23, 8)} \int_{0}^{1} p^{31}(1-p)^{8} dp \\
  &= \frac{10}{B(23, 8)} \int_{0}^{1} p^{32 - 1}(1-p)^{9 - 1} dp \\
  &= \frac{10}{B(23, 8)} B(32, 9) \\
\end{aligned}
$$

```{r}
10 * beta(32, 9) / beta(23, 8)
```

$$
\begin{aligned}
  p(X=10) 
  &= \int_{0}^{1} \binom{10}{10}p^{10}(1-p)^{10-10} Beta(p|23,8) dp \\
  &= \int_{0}^{1} p^{10} Beta(p|23,8) dp \\
  &= \frac{1}{B(23, 8)} \int_{0}^{1} p^{10} p^{22} (1-p)^{7} dp \\
  &= \frac{1}{B(23, 8)} \int_{0}^{1} p^{32}(1-p)^{7} dp \\
  &= \frac{1}{B(23, 8)} \int_{0}^{1} p^{33 - 1}(1-p)^{8 - 1} dp \\
  &= \frac{1}{B(23, 8)} B(33, 8) \\
\end{aligned}
$$

```{r}
beta(33, 8) / beta(23, 8)
```

サンプリングすると以下のようにできる．  
よって、このときの $X = 9 \; or \; X = 10$ となる確率を求めれば良い.

$$
p \sim Beta(p|23, 8) \\
x \sim Bin(x|10, p)
$$

```{r}
p = rbeta(10000, 23, 8)
x = rbinom(10000, 10, p)
table(x) / 10000
```

理論値と近い値となっていることが確認できる．

## 2-4

### (a)

```{r}
p = seq(0.1, 0.5, by=0.1)
p
prior = c(0.50, 0.2, 0.2, 0.05, 0.05)
mean = sum(p * prior)
mean
sd = sqrt(sum((p - mean)^2 * prior))
sd
```

$Beta(p|3, 12)$ の場合、サンプリング近似を行う.

```{r}
sample = rbeta(10000, shape1 = 3, shape2 = 12)
mean(sample)
sd(sample)
```

### (b)

通学者数 $Y$ に関して、以下の予測分布が計算できる.

#### 離散事前分布

$$
p(y) = \sum_p \binom{12}{y} p^{y} (1-p)^{12-y} g(p)
$$

```{r}
predict = c()
for (y in 0:12) {
  p_y = 0
  for (i in 1:length(p)) {  
    p_y = p_y + choose(12, y) * p[i]^y * (1 - p[i])^(12 - y) * prior[i]
  }
  predict = c(predict, p_y)
}
predict
plot(0:12, predict, type = "l")
```

```{r}
pdiscp(p, prior, 12, 0:12)
plot(0:12, pdiscp(p, prior, 12, 0:12), type = "l")
```

#### ベータ分布

$$
\begin{aligned}
  p(y) 
  &= \int_0^1 \binom{12}{y} p^{y} (1-p)^{12-y} \frac{1}{B(3, 12)} p^{3 - 1} (1-p)^{12 - 1} dp \\
  &= \binom{12}{y}  \frac{1}{B(3, 12)}  \int_0^1 p^{y + 2} (1-p)^{23-y} dp \\
  &= \binom{12}{y}  \frac{1}{B(3, 12)}  B(y + 3, 24 - y) \\
\end{aligned}
$$

```{r}
predict = c()
for (y in 0:12) {
  p_y = choose(12, y) * beta(y + 3, 24 - y) / beta(3, 12)
  predict = c(predict, p_y)
}
predict
sum(predict)
plot(0:12, predict, type = "l")
```

```{r}
pbetap(c(3, 12), 12, 0:12)
plot(0:12, pbetap(c(3, 12), 12, 0:12), type = "l")
```

## 2-5

### (a)

```{r}
mu = seq(20, 70, by = 10)
prior = c(0.1, 0.15, 0.25, 0.25, 0.15, 0.1)
mu
prior
```

### (b)

```{r}
y = c(38.6, 42.4, 57.5, 40.5, 51.7, 67.1, 33.4, 60.9, 64.1, 40.1, 40.7, 6.4)
ybar = mean(y)
ybar
```

### (c)

```{r}
likelihood = function (mu) exp(-1 * length(y) / (2 * 100) * (mu - ybar)^2)
like = likelihood(mu)
like
```

### (d)

```{r}
post = prior * like
post = post / sum(post)
post
```

### (e)

```{r}
dist = cbind(mu, post)
dist
discint(dist, 0.8)
```

## 2-6

### (a)

```{r}
lambda = c(0.5, 1, 1.5, 2, 2.5, 3)
prior = c(0.1, 0.2, 0.3, 0.2, 0.15, 0.05)
likelihood = function (lambda) exp(-6 * lambda) * (6 * lambda)^12
post = prior * likelihood(lambda)
post = post / sum(post)
cbind(lambda, prior, round(post, 2))
```

### (b)

$$
p(y|\lambda) = \exp{(-\lambda)}\frac{\lambda^y}{y!}
$$

7 日間故障が起きない確率は、$p(y=0)^7$

$$
p(y=0|\lambda)^7 = \exp{(-\lambda)}^7 = \exp{(-7\lambda)}
$$

よって、予測確率は

$$
p(y=0) = \sum_{\lambda} p(y=0|\lambda) p(\lambda)
$$

```{r}
predict = 0
for (i in 1:length(lambda)) {
  predict = predict + exp(-7 * lambda[i]) * post[i]
}
predict
```
